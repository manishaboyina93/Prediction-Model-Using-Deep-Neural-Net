{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmGmIC-NWCHe"
      },
      "source": [
        "The given dataset contains demographic information about the patients of a clinic.\n",
        "\n",
        "Our target is to generate a neural network model to predict the percentage of patients at the clinic who will use online appointments.\n",
        "\n",
        "**Summary of the model:**\n",
        "\n",
        "1. Relaced cells with values 0f -97 & -98 to NaN.\n",
        "2. Generated a dataframe.\n",
        "3. Dropped the rows with null values. Dropped the ClinicID column fron the dataframe.\n",
        "4. Converted categorical variable (vendor) to numerical variables.\n",
        "5. Divided dataset to train and validation/test sets in 60-40 ratio.\n",
        "6. Generated a baseline model.\n",
        "7. Generated a regularized model.\n",
        "\n",
        "\n",
        "**Naive Approach:** For the given dataset we are to predict the percentage of patients at the clinic who will use online appointments. \n",
        "\n",
        "Thus, the naive approach is that the model's **'Mean Absolute Error' shoud be lesser than the dataset's 'Mean Average Deviation'.** \n",
        "\n",
        "\n",
        "\n",
        "**Baseline Model:**\n",
        "\n",
        "1. The model has 1 Input layer, 6 hidden layers(20 nodes each), 1 Output layer.\n",
        "2. Activation function = ReLu for all layers.\n",
        "3. Loss = MSE, Optimizer = RMSPROP, Metric = MAE\n",
        "4. **The baseline model built has a val_MAE 0.06556 . LOWER than the data's MAD which is 0.6759.**\n",
        "5. Also there doesn't seem to be much of over-fitting.\n",
        "\n",
        "**Regularized model:**\n",
        "\n",
        "1. We increased the number of hidden layers and nodes per layer to the model.\n",
        "2. L1 regularization has been implemented, to identify uninformative features and force their weights to be zero by subtracting a small amount from the weight at each iteration, eventually making it zero.\n",
        "3. Learning rate was determined which is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.\n",
        "4. **The regularized model built has a val_MAE of 0.6758. LOWER than the data's MAD which is 0.6759. But HIGHER than baseline model's val_MAE.**\n",
        "5. Tnere does not seem to be over-fitting.\n",
        "\n",
        "**Analysis:**\n",
        "\n",
        "All the 3 models more or less work efficiently to predict the target variable. However, the baseline model has the least val_MAE. **Hence, we choose the baseline model to be the best model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B846H2gH9JhJ"
      },
      "source": [
        "1. Importing the required liabraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOoPqV85b6zf",
        "outputId": "26351b07-1a88-4e14-87c7-c98e137de6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.X\n",
        "from numpy.random import seed\n",
        "seed(2)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(2)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.data import Dataset\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUW0m99W9JA7"
      },
      "source": [
        "2. Loading the dataset and generating a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTFqc9JGcCod"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "concrete_dataframe = pd.read_excel(\"OnlineUse.xlsx\", \"OnlineUseData\")\n",
        "\n",
        "concrete_dataframe = concrete_dataframe.reindex(np.random.permutation(concrete_dataframe.index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pw8W6U1mcNas",
        "outputId": "8bfafdc4-5123-4c37-d10f-45218745757a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-71670325-cb55-4472-9ad7-0024a29b95ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClinicID</th>\n",
              "      <th>OnlineAppointmentUse</th>\n",
              "      <th>malepct</th>\n",
              "      <th>unemp</th>\n",
              "      <th>age16to24</th>\n",
              "      <th>age25to34</th>\n",
              "      <th>age35to44</th>\n",
              "      <th>age45to54</th>\n",
              "      <th>age55to64</th>\n",
              "      <th>age65to74</th>\n",
              "      <th>...</th>\n",
              "      <th>phoneeasy</th>\n",
              "      <th>onlineasy</th>\n",
              "      <th>race</th>\n",
              "      <th>longstdhealth</th>\n",
              "      <th>canmngownhealth</th>\n",
              "      <th>reducedability</th>\n",
              "      <th>prefgpalways</th>\n",
              "      <th>bcaaware</th>\n",
              "      <th>vendor</th>\n",
              "      <th>numpats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6248</th>\n",
              "      <td>6254</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>7012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4833</th>\n",
              "      <td>4839</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.31</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>13813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>375</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.60</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>13430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>3684</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.47</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>3936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>1721</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.23</td>\n",
              "      <td>...</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.20</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>10525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6443</th>\n",
              "      <td>6449</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.38</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>9462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>3612</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.13</td>\n",
              "      <td>...</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>13159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5704</th>\n",
              "      <td>5710</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.15</td>\n",
              "      <td>...</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.43</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>6054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6637</th>\n",
              "      <td>6643</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.33</td>\n",
              "      <td>TPP</td>\n",
              "      <td>11390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>2581</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.52</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.06</td>\n",
              "      <td>EMIS</td>\n",
              "      <td>2664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6857 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71670325-cb55-4472-9ad7-0024a29b95ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71670325-cb55-4472-9ad7-0024a29b95ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71670325-cb55-4472-9ad7-0024a29b95ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ClinicID  OnlineAppointmentUse  malepct  unemp  age16to24  age25to34  \\\n",
              "6248      6254                  0.23     0.51   0.04       0.05       0.17   \n",
              "4833      4839                  0.02     0.43   0.00       0.08       0.12   \n",
              "369        375                  0.30     0.54   0.07       0.14       0.17   \n",
              "3678      3684                  0.15     0.50   0.06       0.09       0.26   \n",
              "1715      1721                  0.08     0.56   0.02       0.10       0.11   \n",
              "...        ...                   ...      ...    ...        ...        ...   \n",
              "6443      6449                  0.14     0.52   0.00       0.19       0.08   \n",
              "3606      3612                  0.24     0.50   0.03       0.10       0.08   \n",
              "5704      5710                  0.02     0.49   0.03       0.05       0.10   \n",
              "6637      6643                  0.15     0.53   0.08       0.15       0.23   \n",
              "2575      2581                  0.02     0.46   0.02       0.08       0.07   \n",
              "\n",
              "      age35to44  age45to54  age55to64  age65to74  ...  phoneeasy  onlineasy  \\\n",
              "6248       0.28       0.19       0.14       0.11  ...       0.73       0.74   \n",
              "4833       0.12       0.24       0.13       0.14  ...       0.86       0.91   \n",
              "369        0.17       0.16       0.21       0.10  ...       0.79       0.99   \n",
              "3678       0.30       0.13       0.10       0.07  ...       0.94       0.79   \n",
              "1715       0.07       0.12       0.16       0.23  ...       0.85       0.71   \n",
              "...         ...        ...        ...        ...  ...        ...        ...   \n",
              "6443       0.21       0.10       0.16       0.13  ...       0.58       0.79   \n",
              "3606       0.18       0.21       0.18       0.13  ...       0.65       0.83   \n",
              "5704       0.11       0.20       0.23       0.15  ...       0.42       0.62   \n",
              "6637       0.21       0.18       0.09       0.10  ...       0.65       0.63   \n",
              "2575       0.24       0.22       0.16       0.10  ...       0.80       0.35   \n",
              "\n",
              "      race  longstdhealth  canmngownhealth  reducedability  prefgpalways  \\\n",
              "6248  0.60           0.51             0.80            0.66          0.51   \n",
              "4833  0.91           0.55             0.85            0.58          0.49   \n",
              "369   0.90           0.55             0.67            0.87          0.54   \n",
              "3678  0.30           0.45             0.89            0.55          0.78   \n",
              "1715  0.98           0.63             0.80            0.56          0.46   \n",
              "...    ...            ...              ...             ...           ...   \n",
              "6443  0.83           0.57             0.82            0.51          0.59   \n",
              "3606  0.93           0.50             0.93            0.41          0.39   \n",
              "5704  0.97           0.64             0.81            0.57          0.39   \n",
              "6637  0.45           0.45             0.81            0.53          0.27   \n",
              "2575  0.78           0.43             0.82            0.52           NaN   \n",
              "\n",
              "      bcaaware  vendor  numpats  \n",
              "6248      0.56    EMIS     7012  \n",
              "4833      0.31    EMIS    13813  \n",
              "369       0.60    EMIS    13430  \n",
              "3678      0.47    EMIS     3936  \n",
              "1715      0.20    EMIS    10525  \n",
              "...        ...     ...      ...  \n",
              "6443      0.38    EMIS     9462  \n",
              "3606      0.66    EMIS    13159  \n",
              "5704      0.43    EMIS     6054  \n",
              "6637      0.33     TPP    11390  \n",
              "2575      0.06    EMIS     2664  \n",
              "\n",
              "[6857 rows x 22 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concrete_dataframe # Displaying the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wobIrskbcRO8",
        "outputId": "1ac0cc54-eece-4799-bfa4-0f15ef891253"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6857"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concrete_dataframe.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zpce3DT-0x_"
      },
      "source": [
        "3. Dropping observations with no values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktrYKVT1eZV0"
      },
      "outputs": [],
      "source": [
        "# Dropping the rows with missing values.\n",
        "concrete_dataframe = concrete_dataframe.dropna() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P8Ek3DW--fN",
        "outputId": "a87dd8b9-39f0-4d3a-ed74-9e695b6a0526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6360"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concrete_dataframe.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN645Yi44AMV"
      },
      "outputs": [],
      "source": [
        "# Dropping the CliniID column from the dataframe.\n",
        "concrete_dataframe = concrete_dataframe.drop(columns=['ClinicID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HueLceZ5_Gr7",
        "outputId": "035ea52a-985a-4c92-d0d4-2b3220cbf836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OnlineAppointmentUse    float64\n",
            "malepct                 float64\n",
            "unemp                   float64\n",
            "age16to24               float64\n",
            "age25to34               float64\n",
            "                         ...   \n",
            "reducedability          float64\n",
            "prefgpalways            float64\n",
            "bcaaware                float64\n",
            "vendor                   object\n",
            "numpats                   int64\n",
            "Length: 21, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Checking the data types for all columns in the dataframe.\n",
        "print(concrete_dataframe.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67FpLIOd_R9-"
      },
      "source": [
        "4. Converting Object variables above to Integer variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTNoOgQtlRrW"
      },
      "outputs": [],
      "source": [
        "concrete_dataframe[\"vendor\"] = concrete_dataframe[\"vendor\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhYPDHQXt_nC",
        "outputId": "d638b181-4b81-4a62-8435-d38a301ae930"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['EMIS', 'EMIS (I)', 'MICROTEST', 'TPP', 'VISION', 'VISION (I)'], dtype='object')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concrete_dataframe[\"vendor\"].cat.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP08VwCnpjjA"
      },
      "outputs": [],
      "source": [
        "concrete_dataframe[\"vendor\"].replace(['EMIS', 'EMIS (I)', 'MICROTEST', 'TPP', 'VISION', 'VISION (I)'], [0, 1, 2, 3, 4, 5], inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8CRwp7WpjS7",
        "outputId": "737831ce-c64d-473a-d7c2-3767ccd0f33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OnlineAppointmentUse    float64\n",
              "malepct                 float64\n",
              "unemp                   float64\n",
              "age16to24               float64\n",
              "age25to34               float64\n",
              "                         ...   \n",
              "reducedability          float64\n",
              "prefgpalways            float64\n",
              "bcaaware                float64\n",
              "vendor                    int64\n",
              "numpats                   int64\n",
              "Length: 21, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concrete_dataframe[\"vendor\"] = concrete_dataframe[\"vendor\"].astype(\"int64\")\n",
        "concrete_dataframe.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5vNz24Y_n-m"
      },
      "source": [
        "5. Splitting the dataset to training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pgJD4jTRZZoa",
        "outputId": "4e37a860-4864-4b41-cd92-65dc72903065"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e4bcc61a-8c33-4497-adb8-245d6e79708b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malepct</th>\n",
              "      <th>unemp</th>\n",
              "      <th>age16to24</th>\n",
              "      <th>age25to34</th>\n",
              "      <th>age35to44</th>\n",
              "      <th>age45to54</th>\n",
              "      <th>age55to64</th>\n",
              "      <th>age65to74</th>\n",
              "      <th>age75to84</th>\n",
              "      <th>age85plus</th>\n",
              "      <th>phoneeasy</th>\n",
              "      <th>onlineasy</th>\n",
              "      <th>race</th>\n",
              "      <th>longstdhealth</th>\n",
              "      <th>canmngownhealth</th>\n",
              "      <th>reducedability</th>\n",
              "      <th>prefgpalways</th>\n",
              "      <th>bcaaware</th>\n",
              "      <th>vendor</th>\n",
              "      <th>numpats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.28</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>-1.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.42</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.16</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>1.41</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.90</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>1.21</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.81</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.17</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.25</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-1.45</td>\n",
              "      <td>-1.34</td>\n",
              "      <td>-1.15</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-1.79</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>0.72</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.36</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.30</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-1.60</td>\n",
              "      <td>-1.36</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>2.09</td>\n",
              "      <td>2.46</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.30</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-1.36</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6355</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.38</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>0.64</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.45</td>\n",
              "      <td>-0.98</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.81</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.33</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6356</th>\n",
              "      <td>0.52</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>1.54</td>\n",
              "      <td>-1.13</td>\n",
              "      <td>0.80</td>\n",
              "      <td>-1.76</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.14</td>\n",
              "      <td>-0.95</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6357</th>\n",
              "      <td>0.19</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-1.09</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.43</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.69</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>1.17</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>1.54</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6358</th>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>-0.86</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.57</td>\n",
              "      <td>-1.53</td>\n",
              "      <td>-1.25</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1.32</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>0.08</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6359</th>\n",
              "      <td>0.64</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.74</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-1.69</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-1.37</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>-1.22</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6360 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4bcc61a-8c33-4497-adb8-245d6e79708b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4bcc61a-8c33-4497-adb8-245d6e79708b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4bcc61a-8c33-4497-adb8-245d6e79708b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      malepct  unemp  age16to24  age25to34  age35to44  age45to54  age55to64  \\\n",
              "0        0.28   0.06      -1.00       0.12       1.98       0.28      -0.46   \n",
              "1       -1.16  -1.07      -0.45      -0.53      -0.68       1.41      -0.68   \n",
              "2        0.90   0.67       0.63       0.05       0.17      -0.39       1.21   \n",
              "3        0.23   0.41      -0.30       1.35       2.25      -1.06      -1.45   \n",
              "4        1.30  -0.45       0.01      -0.76      -1.60      -1.36      -0.05   \n",
              "...       ...    ...        ...        ...        ...        ...        ...   \n",
              "6355     0.63   0.38      -0.03       0.27      -0.52       0.64      -0.49   \n",
              "6356     0.52  -1.07       1.54      -1.13       0.80      -1.76       0.05   \n",
              "6357     0.19  -0.38      -0.09      -1.09       0.24       0.82       0.44   \n",
              "6358    -0.09  -0.37      -0.92      -0.89      -0.86       0.50       1.64   \n",
              "6359     0.64   0.91       0.84       0.96       0.74      -0.05      -1.69   \n",
              "\n",
              "      age65to74  age75to84  age85plus  phoneeasy  onlineasy  race  \\\n",
              "0         -0.43      -0.83      -1.08       0.09      -0.25 -0.60   \n",
              "1          0.31       0.92       1.87       0.73       1.10  0.60   \n",
              "2         -0.68      -0.68      -1.80       0.40       1.81  0.58   \n",
              "3         -1.34      -1.15      -0.69       1.16       0.18 -1.79   \n",
              "4          2.09       2.46       1.98       0.68      -0.55  0.88   \n",
              "...         ...        ...        ...        ...        ...   ...   \n",
              "6355       0.18       0.45      -0.98       0.90       0.81 -0.84   \n",
              "6356       0.08       0.04       1.10      -0.73       0.14  0.31   \n",
              "6357       0.12       0.43      -0.11      -0.32       0.48  0.69   \n",
              "6358       0.52       0.84       1.57      -1.53      -1.25  0.85   \n",
              "6359      -0.66      -1.37      -0.71      -0.33      -1.18 -1.22   \n",
              "\n",
              "      longstdhealth  canmngownhealth  reducedability  prefgpalways  bcaaware  \\\n",
              "0             -0.21            -0.42            0.67          0.08      0.90   \n",
              "1              0.35             0.17           -0.21         -0.01     -0.68   \n",
              "2              0.26            -1.97            2.90          0.26      1.17   \n",
              "3             -0.93             0.72           -0.46          1.53      0.36   \n",
              "4              1.30            -0.44           -0.33         -0.17     -1.36   \n",
              "...             ...              ...             ...           ...       ...   \n",
              "6355           1.03             0.17           -0.13          0.59      0.33   \n",
              "6356           0.50            -0.14           -0.95          0.50     -0.20   \n",
              "6357          -0.27             1.17           -1.97         -0.56      1.54   \n",
              "6358           1.32            -0.27           -0.24         -0.58      0.08   \n",
              "6359          -0.92            -0.32           -0.68         -1.18     -0.51   \n",
              "\n",
              "      vendor  numpats  \n",
              "0      -0.85    -0.34  \n",
              "1      -0.85     0.92  \n",
              "2      -0.85     0.85  \n",
              "3      -0.85    -0.91  \n",
              "4      -0.85     0.31  \n",
              "...      ...      ...  \n",
              "6355   -0.85    -0.69  \n",
              "6356   -0.85     0.11  \n",
              "6357   -0.85     0.80  \n",
              "6358   -0.85    -0.52  \n",
              "6359    1.11     0.47  \n",
              "\n",
              "[6360 rows x 20 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_df = pd.DataFrame(scaler.fit_transform(concrete_dataframe.drop(['OnlineAppointmentUse'], axis = 1)),\n",
        "                         columns = concrete_dataframe.drop(['OnlineAppointmentUse'], axis = 1).columns)\n",
        "# Category and Sex are categorical variables and hence need not get scaled\n",
        "scaled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "6g1MvxJKZZjA",
        "outputId": "862e3933-c99d-46c7-de0e-4e32fa69aa3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc55cb64-2ee3-4488-b45d-acf5eb977a52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OnlineAppointmentUse</th>\n",
              "      <th>malepct</th>\n",
              "      <th>unemp</th>\n",
              "      <th>age16to24</th>\n",
              "      <th>age25to34</th>\n",
              "      <th>age35to44</th>\n",
              "      <th>age45to54</th>\n",
              "      <th>age55to64</th>\n",
              "      <th>age65to74</th>\n",
              "      <th>age75to84</th>\n",
              "      <th>...</th>\n",
              "      <th>phoneeasy</th>\n",
              "      <th>onlineasy</th>\n",
              "      <th>race</th>\n",
              "      <th>longstdhealth</th>\n",
              "      <th>canmngownhealth</th>\n",
              "      <th>reducedability</th>\n",
              "      <th>prefgpalways</th>\n",
              "      <th>bcaaware</th>\n",
              "      <th>vendor</th>\n",
              "      <th>numpats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.06</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.28</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.43</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.42</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.90</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.13</td>\n",
              "      <td>-1.16</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>1.41</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.92</td>\n",
              "      <td>...</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.17</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>1.21</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>...</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.81</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.26</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.17</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.41</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.25</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-1.45</td>\n",
              "      <td>-1.34</td>\n",
              "      <td>-1.15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.18</td>\n",
              "      <td>-1.79</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>0.72</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.36</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>1.30</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-1.60</td>\n",
              "      <td>-1.36</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>2.09</td>\n",
              "      <td>2.46</td>\n",
              "      <td>...</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-0.55</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.30</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>-1.36</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6851</th>\n",
              "      <td>0.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6852</th>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6853</th>\n",
              "      <td>0.13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6855</th>\n",
              "      <td>0.14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6856</th>\n",
              "      <td>0.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6782 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc55cb64-2ee3-4488-b45d-acf5eb977a52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc55cb64-2ee3-4488-b45d-acf5eb977a52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc55cb64-2ee3-4488-b45d-acf5eb977a52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      OnlineAppointmentUse  malepct  unemp  age16to24  age25to34  age35to44  \\\n",
              "0                     0.06     0.28   0.06      -1.00       0.12       1.98   \n",
              "1                     0.13    -1.16  -1.07      -0.45      -0.53      -0.68   \n",
              "2                     0.06     0.90   0.67       0.63       0.05       0.17   \n",
              "3                     0.10     0.23   0.41      -0.30       1.35       2.25   \n",
              "4                     0.10     1.30  -0.45       0.01      -0.76      -1.60   \n",
              "...                    ...      ...    ...        ...        ...        ...   \n",
              "6851                  0.05      NaN    NaN        NaN        NaN        NaN   \n",
              "6852                  0.15      NaN    NaN        NaN        NaN        NaN   \n",
              "6853                  0.13      NaN    NaN        NaN        NaN        NaN   \n",
              "6855                  0.14      NaN    NaN        NaN        NaN        NaN   \n",
              "6856                  0.01      NaN    NaN        NaN        NaN        NaN   \n",
              "\n",
              "      age45to54  age55to64  age65to74  age75to84  ...  phoneeasy  onlineasy  \\\n",
              "0          0.28      -0.46      -0.43      -0.83  ...       0.09      -0.25   \n",
              "1          1.41      -0.68       0.31       0.92  ...       0.73       1.10   \n",
              "2         -0.39       1.21      -0.68      -0.68  ...       0.40       1.81   \n",
              "3         -1.06      -1.45      -1.34      -1.15  ...       1.16       0.18   \n",
              "4         -1.36      -0.05       2.09       2.46  ...       0.68      -0.55   \n",
              "...         ...        ...        ...        ...  ...        ...        ...   \n",
              "6851        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
              "6852        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
              "6853        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
              "6855        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
              "6856        NaN        NaN        NaN        NaN  ...        NaN        NaN   \n",
              "\n",
              "      race  longstdhealth  canmngownhealth  reducedability  prefgpalways  \\\n",
              "0    -0.60          -0.21            -0.42            0.67          0.08   \n",
              "1     0.60           0.35             0.17           -0.21         -0.01   \n",
              "2     0.58           0.26            -1.97            2.90          0.26   \n",
              "3    -1.79          -0.93             0.72           -0.46          1.53   \n",
              "4     0.88           1.30            -0.44           -0.33         -0.17   \n",
              "...    ...            ...              ...             ...           ...   \n",
              "6851   NaN            NaN              NaN             NaN           NaN   \n",
              "6852   NaN            NaN              NaN             NaN           NaN   \n",
              "6853   NaN            NaN              NaN             NaN           NaN   \n",
              "6855   NaN            NaN              NaN             NaN           NaN   \n",
              "6856   NaN            NaN              NaN             NaN           NaN   \n",
              "\n",
              "      bcaaware  vendor  numpats  \n",
              "0         0.90   -0.85    -0.34  \n",
              "1        -0.68   -0.85     0.92  \n",
              "2         1.17   -0.85     0.85  \n",
              "3         0.36   -0.85    -0.91  \n",
              "4        -1.36   -0.85     0.31  \n",
              "...        ...     ...      ...  \n",
              "6851       NaN     NaN      NaN  \n",
              "6852       NaN     NaN      NaN  \n",
              "6853       NaN     NaN      NaN  \n",
              "6855       NaN     NaN      NaN  \n",
              "6856       NaN     NaN      NaN  \n",
              "\n",
              "[6782 rows x 21 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=concrete_dataframe[['OnlineAppointmentUse']]\n",
        "\n",
        "concrete_dataframe = pd.concat([df,scaled_df],axis = 1)\n",
        "concrete_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX08fA-zZZdO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2cl8XgnZZT1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG2vZLlTcXMN"
      },
      "outputs": [],
      "source": [
        "x = concrete_dataframe.drop(columns=[\"OnlineAppointmentUse\"])\n",
        "y = concrete_dataframe[\"OnlineAppointmentUse\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmNtd0cD_9pl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.4, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n_ROElZIcYvE",
        "outputId": "a5054ca3-6d90-4f33-c8ec-96e906c8269c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training examples summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-946b9058-9749-47c1-8bce-8d6ccb5596ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malepct</th>\n",
              "      <th>unemp</th>\n",
              "      <th>age16to24</th>\n",
              "      <th>age25to34</th>\n",
              "      <th>age35to44</th>\n",
              "      <th>age45to54</th>\n",
              "      <th>age55to64</th>\n",
              "      <th>age65to74</th>\n",
              "      <th>age75to84</th>\n",
              "      <th>age85plus</th>\n",
              "      <th>phoneeasy</th>\n",
              "      <th>onlineasy</th>\n",
              "      <th>race</th>\n",
              "      <th>longstdhealth</th>\n",
              "      <th>canmngownhealth</th>\n",
              "      <th>reducedability</th>\n",
              "      <th>prefgpalways</th>\n",
              "      <th>bcaaware</th>\n",
              "      <th>vendor</th>\n",
              "      <th>numpats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "      <td>3805.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.99</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.55</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>-1.88</td>\n",
              "      <td>-2.21</td>\n",
              "      <td>-2.40</td>\n",
              "      <td>-3.33</td>\n",
              "      <td>-3.27</td>\n",
              "      <td>-2.73</td>\n",
              "      <td>-2.31</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>-3.21</td>\n",
              "      <td>-4.75</td>\n",
              "      <td>-2.96</td>\n",
              "      <td>-3.78</td>\n",
              "      <td>-5.39</td>\n",
              "      <td>-3.17</td>\n",
              "      <td>-2.54</td>\n",
              "      <td>-2.55</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.63</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.13</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.09</td>\n",
              "      <td>12.88</td>\n",
              "      <td>10.95</td>\n",
              "      <td>5.50</td>\n",
              "      <td>4.68</td>\n",
              "      <td>4.10</td>\n",
              "      <td>3.62</td>\n",
              "      <td>3.36</td>\n",
              "      <td>3.78</td>\n",
              "      <td>4.90</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.68</td>\n",
              "      <td>2.05</td>\n",
              "      <td>4.21</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.91</td>\n",
              "      <td>2.41</td>\n",
              "      <td>12.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-946b9058-9749-47c1-8bce-8d6ccb5596ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-946b9058-9749-47c1-8bce-8d6ccb5596ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-946b9058-9749-47c1-8bce-8d6ccb5596ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       malepct   unemp  age16to24  age25to34  age35to44  age45to54  age55to64  \\\n",
              "count  3805.00 3805.00    3805.00    3805.00    3805.00    3805.00    3805.00   \n",
              "mean      0.01    0.01      -0.02       0.01       0.01      -0.01      -0.01   \n",
              "std       0.99    1.02       0.99       0.99       1.00       0.99       0.99   \n",
              "min      -3.55   -1.07      -1.88      -2.21      -2.40      -3.33      -3.27   \n",
              "25%      -0.63   -0.73      -0.67      -0.69      -0.71      -0.67      -0.64   \n",
              "50%      -0.02   -0.27      -0.13      -0.11      -0.10      -0.01       0.04   \n",
              "75%       0.63    0.48       0.47       0.57       0.64       0.61       0.62   \n",
              "max       5.09   12.88      10.95       5.50       4.68       4.10       3.62   \n",
              "\n",
              "       age65to74  age75to84  age85plus  phoneeasy  onlineasy    race  \\\n",
              "count    3805.00    3805.00    3805.00    3805.00    3805.00 3805.00   \n",
              "mean        0.01       0.00       0.01      -0.00      -0.00    0.00   \n",
              "std         0.99       0.99       1.00       0.99       0.99    1.00   \n",
              "min        -2.73      -2.31      -1.80      -3.21      -4.75   -2.96   \n",
              "25%        -0.64      -0.70      -0.71      -0.69      -0.60   -0.49   \n",
              "50%         0.00      -0.02      -0.11       0.15       0.12    0.44   \n",
              "75%         0.68       0.66       0.62       0.81       0.72    0.75   \n",
              "max         3.36       3.78       4.90       1.48       1.87    0.97   \n",
              "\n",
              "       longstdhealth  canmngownhealth  reducedability  prefgpalways  bcaaware  \\\n",
              "count        3805.00          3805.00         3805.00       3805.00   3805.00   \n",
              "mean            0.01            -0.00            0.00         -0.02      0.00   \n",
              "std             1.01             1.01            1.00          1.00      1.00   \n",
              "min            -3.78            -5.39           -3.17         -2.54     -2.55   \n",
              "25%            -0.64            -0.57           -0.70         -0.74     -0.73   \n",
              "50%             0.05             0.13           -0.01         -0.08      0.01   \n",
              "75%             0.67             0.75            0.68          0.67      0.70   \n",
              "max             5.68             2.05            4.21          2.60      2.91   \n",
              "\n",
              "       vendor  numpats  \n",
              "count 3805.00  3805.00  \n",
              "mean    -0.00     0.01  \n",
              "std      1.00     1.02  \n",
              "min     -0.85    -1.41  \n",
              "25%     -0.85    -0.69  \n",
              "50%     -0.85    -0.19  \n",
              "75%      1.11     0.46  \n",
              "max      2.41    12.00  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation examples summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f5f1a86-2d03-4f6d-8f19-c0f12d207ecd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malepct</th>\n",
              "      <th>unemp</th>\n",
              "      <th>age16to24</th>\n",
              "      <th>age25to34</th>\n",
              "      <th>age35to44</th>\n",
              "      <th>age45to54</th>\n",
              "      <th>age55to64</th>\n",
              "      <th>age65to74</th>\n",
              "      <th>age75to84</th>\n",
              "      <th>age85plus</th>\n",
              "      <th>phoneeasy</th>\n",
              "      <th>onlineasy</th>\n",
              "      <th>race</th>\n",
              "      <th>longstdhealth</th>\n",
              "      <th>canmngownhealth</th>\n",
              "      <th>reducedability</th>\n",
              "      <th>prefgpalways</th>\n",
              "      <th>bcaaware</th>\n",
              "      <th>vendor</th>\n",
              "      <th>numpats</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "      <td>2555.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.01</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.35</td>\n",
              "      <td>-1.07</td>\n",
              "      <td>-1.88</td>\n",
              "      <td>-2.21</td>\n",
              "      <td>-2.40</td>\n",
              "      <td>-4.25</td>\n",
              "      <td>-3.55</td>\n",
              "      <td>-2.73</td>\n",
              "      <td>-2.31</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>-3.41</td>\n",
              "      <td>-6.38</td>\n",
              "      <td>-2.98</td>\n",
              "      <td>-3.85</td>\n",
              "      <td>-6.02</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>-2.40</td>\n",
              "      <td>-2.59</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-1.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.74</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>-0.72</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.14</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.40</td>\n",
              "      <td>4.88</td>\n",
              "      <td>11.29</td>\n",
              "      <td>7.21</td>\n",
              "      <td>4.23</td>\n",
              "      <td>4.13</td>\n",
              "      <td>3.52</td>\n",
              "      <td>3.87</td>\n",
              "      <td>3.62</td>\n",
              "      <td>6.61</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.97</td>\n",
              "      <td>3.08</td>\n",
              "      <td>2.05</td>\n",
              "      <td>4.21</td>\n",
              "      <td>2.61</td>\n",
              "      <td>2.94</td>\n",
              "      <td>2.41</td>\n",
              "      <td>9.20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f5f1a86-2d03-4f6d-8f19-c0f12d207ecd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f5f1a86-2d03-4f6d-8f19-c0f12d207ecd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f5f1a86-2d03-4f6d-8f19-c0f12d207ecd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       malepct   unemp  age16to24  age25to34  age35to44  age45to54  age55to64  \\\n",
              "count  2555.00 2555.00    2555.00    2555.00    2555.00    2555.00    2555.00   \n",
              "mean     -0.02   -0.01       0.03      -0.01      -0.01       0.01       0.01   \n",
              "std       1.01    0.98       1.02       1.01       1.00       1.01       1.01   \n",
              "min      -4.35   -1.07      -1.88      -2.21      -2.40      -4.25      -3.55   \n",
              "25%      -0.70   -0.73      -0.61      -0.73      -0.74      -0.66      -0.63   \n",
              "50%      -0.04   -0.27      -0.11      -0.15      -0.12      -0.02       0.05   \n",
              "75%       0.60    0.44       0.49       0.55       0.60       0.66       0.67   \n",
              "max       4.40    4.88      11.29       7.21       4.23       4.13       3.52   \n",
              "\n",
              "       age65to74  age75to84  age85plus  phoneeasy  onlineasy    race  \\\n",
              "count    2555.00    2555.00    2555.00    2555.00    2555.00 2555.00   \n",
              "mean       -0.01      -0.00      -0.01       0.00       0.01   -0.00   \n",
              "std         1.01       1.01       1.00       1.02       1.01    1.00   \n",
              "min        -2.73      -2.31      -1.80      -3.41      -6.38   -2.98   \n",
              "25%        -0.70      -0.72      -0.71      -0.68      -0.60   -0.52   \n",
              "50%         0.01      -0.01      -0.12       0.16       0.15    0.45   \n",
              "75%         0.66       0.66       0.58       0.84       0.73    0.75   \n",
              "max         3.87       3.62       6.61       1.48       1.87    0.97   \n",
              "\n",
              "       longstdhealth  canmngownhealth  reducedability  prefgpalways  bcaaware  \\\n",
              "count        2555.00          2555.00         2555.00       2555.00   2555.00   \n",
              "mean           -0.01             0.00           -0.00          0.03     -0.01   \n",
              "std             0.99             0.99            1.00          1.00      1.01   \n",
              "min            -3.85            -6.02           -3.12         -2.40     -2.59   \n",
              "25%            -0.64            -0.56           -0.69         -0.72     -0.73   \n",
              "50%             0.04             0.14           -0.03         -0.00     -0.01   \n",
              "75%             0.70             0.72            0.68          0.75      0.73   \n",
              "max             3.08             2.05            4.21          2.61      2.94   \n",
              "\n",
              "       vendor  numpats  \n",
              "count 2555.00  2555.00  \n",
              "mean     0.01    -0.02  \n",
              "std      1.01     0.97  \n",
              "min     -0.85    -1.34  \n",
              "25%     -0.85    -0.70  \n",
              "50%     -0.85    -0.21  \n",
              "75%      1.11     0.44  \n",
              "max      2.41     9.20  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training targets summary:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "count   3819.00\n",
              "mean       0.14\n",
              "std        0.09\n",
              "min        0.00\n",
              "25%        0.07\n",
              "50%        0.12\n",
              "75%        0.19\n",
              "max        0.62\n",
              "Name: OnlineAppointmentUse, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation targets summary:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "count   2541.00\n",
              "mean       0.14\n",
              "std        0.09\n",
              "min        0.00\n",
              "25%        0.07\n",
              "50%        0.12\n",
              "75%        0.19\n",
              "max        0.61\n",
              "Name: OnlineAppointmentUse, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Printing the first few rows of the training data\n",
        "print(\"Training examples summary:\")\n",
        "display.display(train_x.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(valid_x.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(train_y.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(valid_y.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoPfdX80BUKn"
      },
      "source": [
        "6. Determimg the baseline model and fitting the data to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCb3VnpXAH6V"
      },
      "outputs": [],
      "source": [
        "baseline_model = keras.Sequential([ \n",
        "    keras.layers.Dense(20, activation=tf.nn.relu, input_shape=(train_x.shape[1],)),\n",
        "    # Input Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 1st Hidden Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 2nd Hidden Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 3rd Hidden Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 4th Hidden Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 5th Hidden Layer\n",
        "    keras.layers.Dense(20, activation=tf.nn.relu,), # 6th Hidden Layer\n",
        "    keras.layers.Dense(1)]) # Output Layer\n",
        "\n",
        "\n",
        "baseline_model.compile(loss='mse', \n",
        "                optimizer=\"rmsprop\", \n",
        "                metrics=['mae']) \n",
        "\n",
        " # The most commonly used loss function for regression. The loss is the mean \n",
        " # overseen data of the squared differences between true and predicted values.\n",
        "\n",
        " # Mean Absolute Error (MAE) is a popular metric because the units \n",
        " # of the error score match the units of the target value that is being predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj4SAKFSAH0q",
        "outputId": "0d9d4a33-9a02-442e-f3e8-3e291ac11e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                420       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,961\n",
            "Trainable params: 2,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "baseline_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_I2nq-OAHx5",
        "outputId": "bc8ceba3-9c66-496f-c18d-035fc5a689e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "128/128 [==============================] - 2s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 2/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 3/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 4/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 5/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 6/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 7/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 8/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 9/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 10/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 11/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 12/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 13/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 14/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 15/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 16/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 17/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 18/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 19/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 20/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 21/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 22/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 23/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 24/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 25/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 26/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 27/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 28/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 29/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 30/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 31/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 32/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 33/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 34/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 35/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 36/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 37/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 38/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 39/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 40/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 41/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 42/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 43/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 44/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 45/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 46/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 47/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 48/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 49/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 50/100\n",
            "128/128 [==============================] - 1s 8ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 51/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 52/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 53/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 54/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 55/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 56/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 57/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 58/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 59/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 60/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 61/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 62/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 63/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 64/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 65/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 66/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 67/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 68/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 69/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 70/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 71/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 72/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 73/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 74/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 75/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 76/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 77/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 78/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 79/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 80/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 81/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 82/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 83/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 84/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 85/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 86/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 87/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 88/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 89/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 90/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 91/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 92/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 93/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 94/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 95/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 96/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 97/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 98/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 99/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 100/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "baseline_history = baseline_model.fit(train_x,\n",
        "                    train_y,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_x, valid_y))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KepUpwkwAHrt",
        "outputId": "beaa1a6f-9464-4e8d-b88d-285c6ac2b23b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(min(baseline_history.history['val_mae']))  # ACCURACY OF THE BASELINE_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HvUgUkdCZyq",
        "outputId": "16469b98-4b8d-4789-8ef9-b904dbc31b68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0676119464239628"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y.mad() # mean average deviation (error if I use the average for prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "9rhW1SJQCZlq",
        "outputId": "309be104-4cae-4713-a985-b59401bc59e3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAJRCAYAAABFteoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de/DddX3n8dc74ReDoAXSoEDchk5FbiEx/NBkVaBSDF0uithVFoq0ZakdFHAocu2sjus4u8N0XVwHKnjB0RU0NmJrFouK4iUqCUIJl1rHBQ1S/EGXhKBoEj77x+9AuYaEXM7nFx6PmUzO+Z5zvt/3LznznTzzPd/vqdZaAAAAoFeThj0AAAAArI9wBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBr2w1z41V1Z5IHk6xLsra1NjrMeQAAAOjPUMN14Pdba/cNewgAAAD65KPCAAAAdG3Y4dqS/ENVLauqU4c8CwAAAB0a9keFX9tau7uqdk1ybVXd0Vq7/vFPGATtqUmyww47HLj33nsPY04AAAC2sGXLlt3XWpv+5OXVWhvGPE9RVe9Nsrq1dtEzPWd0dLQtXbp06w0FAADAVlNVy57uor1D+6hwVe1QVS969HaSNyRZPqx5AAAA6NMwPyr8kiSLqurROf53a+2aIc4DAABAh4YWrq21nySZPaztAwAAMDEM++JMAAAAm9WaNWuyYsWKPPzww8MehWcwderUzJgxIyMjIxv0fOEKAABsU1asWJEXvehFmTlzZganJtKR1lruv//+rFixInvuuecGvWbY3+MKAACwWT388MOZNm2aaO1UVWXatGkbdURcuAIAANsc0dq3jf37Ea4AAACb2eTJkzNnzpzMnj07c+fOzXe/+93Nuv6TTz45CxcuTJKccsopue222zZpfb/85S8zbdq0rFq16gnL3/SmN+Wqq656xtftuOOOm7TdDSVcAQAANrPtt98+N910U26++eZ88IMfzHnnnbfFtnX55Zdn33333aR1vPCFL8yCBQuyaNGix5atXLky3/72t3P00Udv6oibTLgCAABsQatWrcrOO++cJFm9enUOO+ywzJ07N7NmzcrVV1+dJHnooYdy5JFHZvbs2dl///0fO8q5bNmyHHLIITnwwAOzYMGC3HPPPU9Z/6GHHpqlS5cmGT8CesEFF2T27NmZN29e7r333iTJ2NhYjjvuuBx00EE56KCD8p3vfOcp6zn++ONz5ZVXPnZ/0aJFWbBgQR555JGnnXlrclVhAACAzexXv/pV5syZk4cffjj33HNPvv71rycZ/xqYRYsW5cUvfnHuu+++zJs3L8ccc0yuueaa7L777vnyl7+cZPxo55o1a/Kud70rV199daZPn56rrroqF1xwQT7+8Y8/43YfeuihzJs3Lx/4wAfynve8J5dddlkuvPDCnHHGGXn3u9+d1772tfnpT3+aBQsW5Pbbb3/CaxcsWJBTTjkl999/f6ZNm5Yrr7wy73znO59x5q15HrFwBQAAtmlv/ZslT1l21AG75Y/nz8yvfrMuJ3/iB095/C0Hzsgfjb4s//rQb/IXn172hMeu+vP5z7rNRz8qnCRLlizJSSedlOXLl6e1lvPPPz/XX399Jk2alLvvvjv33ntvZs2albPOOivnnHNOjjrqqLzuda/L8uXLs3z58hx++OFJknXr1mW33XZb73anTJmSo446Kkly4IEH5tprr02SfPWrX33CebCrVq3K6tWrn3CO6pQpU3LMMcdk4cKFOe644/LDH/4wCxYseMaZX/rSlz7rn8PmIlwBAAC2oPnz5+e+++7L2NhYFi9enLGxsSxbtiwjIyOZOXNmHn744ey111658cYbs3jx4lx44YU57LDDcuyxx2a//fbLkiVPDe9nMjIy8tiR0MmTJ2ft2rVJkkceeSTf+973MnXq1PW+/vjjj8/73//+tNbyxje+MSMjI/nkJz/5tDNvTcIVAADYpq3vCOn2Uyav9/FddpiyQUdY1+eOO+7IunXrMm3atKxcuTK77rprRkZGct111+Wuu+5Kkvz85z/PLrvskhNPPDE77bRTLr/88px77rkZGxvLkiVLMn/+/KxZsyY/+tGPst9++230DG94wxvy4Q9/OGeffXaS5KabbsqcOXOe8rxDDz00J510Uj7ykY/k4osvTpJnnHlrEq4AAACb2aPnuCZJay1XXHFFJk+enBNOOCFHH310Zs2aldHR0ey9995JkltuuSVnn312Jk2alJGRkVxyySWZMmVKFi5cmNNPPz0rV67M2rVrc+aZZz6ncL344otz2mmn5YADDsjatWtz8MEH59JLL33K8yZNmpS3vOUt+dznPpdDDjkkSZ5x5q2pWmtbfaPP1ejoaHv0alkAAABP5/bbb88+++wz7DF4Fk/391RVy1pro09+rq/DAQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAIDNbPLkyZkzZ05mz56duXPn5rvf/e5mXf/JJ5+chQsXJklOOeWU3HbbbZu0vq985SuZM2dO5syZkx133DGveMUrMmfOnJx00kkb9PpLL700n/rUpzZphvXZboutGQAA4Hlq++23z0033ZRkPArPO++8fPOb39wi27r88ss3eR0LFizIggULkiSHHnpoLrroooyOPvHrVNetW5fJkyc/7evf8Y53bPIM6+OIKwAAwBa0atWq7LzzzkmS1atX57DDDsvcuXMza9asXH311UmShx56KEceeWRmz56d/fffP1dddVWSZNmyZTnkkENy4IEHZsGCBbnnnnuesv5DDz00S5cuTZLsuOOOueCCCzJ79uzMmzcv9957b5JkbGwsxx13XA466KAcdNBB+c53vrNBs8+cOTPnnHNO5s6dm89//vO57LLLctBBB2X27Nk57rjj8stf/jJJ8t73vjcXXXTRY/Occ845edWrXpW99tor3/rWtzbhT2+ccAUAANjMfvWrX2XOnDnZe++9c8opp+Sv/uqvkiRTp07NokWLcuONN+a6667LWWedldZarrnmmuy+++65+eabs3z58hxxxBFZs2ZN3vWud2XhwoVZtmxZ/vRP/zQXXHDBerf70EMPZd68ebn55ptz8MEH57LLLkuSnHHGGXn3u9+dG264IV/4whdyyimnbPDPMm3atNx4441529velje/+c254YYbcvPNN2efffbJxz72sad9zdq1a/ODH/wgH/rQh/K+971vg7f1THxUGAAA2Ga97+9uzW0/X7VZ17nv7i/Ofzl6v/U+5/EfFV6yZElOOumkLF++PK21nH/++bn++uszadKk3H333bn33nsza9asnHXWWTnnnHNy1FFH5XWve12WL1+e5cuX5/DDD08y/lHd3Xbbbb3bnTJlSo466qgkyYEHHphrr702SfLVr371CefBrlq1KqtXr86OO+74rD/vW9/61sduL1++PBdeeGEeeOCBrF69+rGPFz/Zm9/85sdmuPPOO591G89GuAIAAGxB8+fPz3333ZexsbEsXrw4Y2NjWbZsWUZGRjJz5sw8/PDD2WuvvXLjjTdm8eLFufDCC3PYYYfl2GOPzX777ZclS5Zs8LZGRkZSVUnGLxC1du3aJMkjjzyS733ve5k6depGz7/DDjs8dvvkk0/OF7/4xcyePTuf/OQn841vfONpX/OCF7zgKTNsCuEKAABss57tyOjWcMcdd2TdunWZNm1aVq5cmV133TUjIyO57rrrctdddyVJfv7zn2eXXXbJiSeemJ122imXX355zj333IyNjWXJkiWZP39+1qxZkx/96EfZb7+N/5ne8IY35MMf/nDOPvvsJMlNN92UOXPmbPR6Hnzwwey2225Zs2ZNPvOZz2SPPfbY6HU8F8IVAABgM3v0HNckaa3liiuuyOTJk3PCCSfk6KOPzqxZszI6Opq99947SXLLLbfk7LPPzqRJkzIyMpJLLrkkU6ZMycKFC3P66adn5cqVWbt2bc4888znFK4XX3xxTjvttBxwwAFZu3ZtDj744Fx66aUbvZ73v//9efWrX53p06fn1a9+dR588MGNXsdzUa21rbKhzWF0dLQ9erUsAACAp3P77bdnn332GfYYPIun+3uqqmWttdEnP9dVhQEAAOiacAUAAKBrwhUAAICuCVcAAGCbM5Gu5fN8tLF/P8IVAADYpkydOjX333+/eO1Uay3333//Rn2nrK/DAQAAtikzZszIihUrMjY2NuxReAZTp07NjBkzNvj5whUAANimjIyMZM899xz2GGxGPioMAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0bejhWlWTq+qHVfX3w54FAACA/gw9XJOckeT2YQ8BAABAn4YarlU1I8mRSS4f5hwAAAD0a9hHXD+U5D1JHhnyHAAAAHRqaOFaVUcl+UVrbdmzPO/UqlpaVUvHxsa20nQAAAD0YphHXF+T5JiqujPJlUleX1WffvKTWmsfba2NttZGp0+fvrVnBAAAYMiGFq6ttfNaazNaazOTvC3J11trJw5rHgAAAPo07HNcAQAAYL22G/YASdJa+0aSbwx5DAAAADrkiCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0bWrhW1dSq+kFV3VxVt1bV+4Y1CwAAAP3abojb/nWS17fWVlfVSJJvV9X/aa19b4gzAQAA0JmhhWtrrSVZPbg7MvjVhjUPAAAAfRrqOa5VNbmqbkryiyTXtta+P8x5AAAA6M9Qw7W1tq61NifJjCSvqqr9n/ycqjq1qpZW1dKxsbGtPyQAAABD1cVVhVtrDyS5LskRT/PYR1tro6210enTp2/94QAAABiqYV5VeHpV7TS4vX2Sw5PcMax5AAAA6NMwryq8W5IrqmpyxgP6c621vx/iPAAAAHRomFcV/sckrxzW9gEAAJgYujjHFQAAAJ6JcAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADo2gaHa1X9TlX9weD29lX1oi03FgAAAIzboHCtqv+cZGGSvxksmpHki1tqKAAAAHjUhh5xPS3Ja5KsSpLW2j8n2XVLDQUAAACP2tBw/XVr7TeP3qmq7ZK0LTMSAAAA/JsNDddvVtX5SbavqsOTfD7J3225sQAAAGDchobruUnGktyS5M+TLE5y4aZsuKpeVlXXVdVtVXVrVZ2xKesDAABg27TdhjyptfZIkssGvzaXtUnOaq3dOLhC8bKqura1dttm3AYAAAAT3AaFa1W9PMkHk+ybZOqjy1trv/tcN9xauyfJPYPbD1bV7Un2SCJcAQAAeMyGflT4E0kuyfhR0t9P8qkkn95cQ1TVzCSvTPL9zbVOAAAAtg0bGq7bt9a+lqRaa3e11t6b5MjNMUBV7ZjkC0nObK2teprHT62qpVW1dGxsbHNsEgAAgAlkg78Op6omJfnnqnpnVR2bZMdN3XhVjWQ8Wj/TWvvbp3tOa+2jrbXR1tro9OnTN3WTAAAATDAbGq5nJHlhktOTHJjkj5O8fVM2XFWV5GNJbm+t/fWmrAsAAIBt14ZeVfiGwc3VSf5kM237NRkP4Fuq6qbBsvNba4s30/oBAADYBqw3XKvqS+t7vLV2zHPdcGvt20nqub4eAACA54dnO+I6P8nPknw241f8FZoAAABsVc8Wri9NcniS45P8pyRfTvLZ1tqtW3owAAAASJ7l4kyttXWttWtaa29PMi/Jj5N8o6reuVWmAwAA4HnvWS/OVFUvyPh3th6fZGaSi5Ms2rJjAQAAwLhnuzjTp5Lsn2Rxkve11pZvlakAAABg4NmOuJ6Y5KGMf4/r6eNfvZpk/CJNrbX24i04GwAAAKw/XFtr6z0HFgAAALY0YQoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0bajhWlUfr6pfVNXyYc4BAABAv4Z9xPWTSY4Y8gwAAAB0bKjh2lq7Psm/DnMGAAAA+jbsI64AAACwXt2Ha1WdWlVLq2rp2NjYsMcBAABgK+s+XFtrH22tjbbWRqdPnz7scQAAANjKug9XAAAAnt+G/XU4n02yJMkrqmpFVf3ZMOcBAACgP9sNc+OtteOHuX0AAAD656PCAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0TbgCAADQNeEKAABA14QrAAAAXROuAAAAdE24AgAA0DXhCgAAQNeEKwAAAF0TrgAAAHRNuAIAANA14QoAAEDXhCsAAABdE64AAAB0bajhWlVHVNU/VdWPq+rcYc4CAABAn4YWrlU1OclHkvxhkn2THF9V+w5rHgAAAPo0zCOur0ry49baT1prv0lyZZI3DnEeAAAAOjTMcN0jyc8ed3/FYBkAAAA8pvuLM1XVqVW1tKqWjo2NDXscAAAAtrJhhuvdSV72uPszBsueoLX20dbaaGttdPr06VttOAAAAPowzHC9IcnLq2rPqpqS5G1JvjTEeQAAAOjQdsPacGttbVW9M8lXkkxO8vHW2q3DmgcAAIA+DS1ck6S1tjjJ4mHOAAAAQN+6vzgTAAAAz2/CFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArglXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC6JlwBAADomnAFAACga8IVAACArg0lXKvqj6rq1qp6pKpGhzEDAAAAE8OwjrguT/LmJNcPafsAAABMENsNY6OttduTpKqGsXkAAAAmEOe4AgAA0LUtdsS1qr6a5KVP89AFrbWrN2I9pyY5dXD311W1fHPMBx347ST3DXsI2Iy8p9mWeD+zLfF+ZiL5nadbWK21rT3Iv2286htJ/rK1tnQDn7+0teZiTmwTvJ/Z1nhPsy3xfmZb4v3MtsBHhQEAAOjasL4O59iqWpFkfpIvV9VXhjEHAAAA/RvWVYUXJVn0HF760c09CwyR9zPbGu9ptiXez2xLvJ+Z8IZ6jisAAAA8G+e4AgAA0LUJEa5VdURV/VNV/biqzh32PLCxquplVXVdVd1WVbdW1RmD5btU1bVV9c+D33ce9qywoapqclX9sKr+fnB/z6r6/mBffVVVTRn2jLAhqmqnqlpYVXdU1e1VNd/+mYmsqt49+PfG8qr6bFVNtY9mous+XKtqcpKPJPnDJPsmOb6q9h3uVLDR1iY5q7W2b5J5SU4bvI/PTfK11trLk3xtcB8mijOS3P64+/8tyf9orf1ekv+X5M+GMhVsvP+Z5JrW2t5JZmf8fW3/zIRUVXskOT3JaGtt/ySTk7wt9tFMcN2Ha5JXJflxa+0nrbXfJLkyyRuHPBNslNbaPa21Gwe3H8z4P4r2yPh7+YrB065I8qbhTAgbp6pmJDkyyeWD+5Xk9UkWDp7i/cyEUFW/leTgJB9Lktbab1prD8T+mYltuyTbV9V2SV6Y5J7YRzPBTYRw3SPJzx53f8VgGUxIVTUzySuTfD/JS1pr9wwe+pckLxnSWLCxPpTkPUkeGdyfluSB1trawX37aiaKPZOMJfnE4KPvl1fVDrF/ZoJqrd2d5KIkP814sK5Msiz20UxwEyFcYZtRVTsm+UKSM1trqx7/WBu/xLfLfNO9qjoqyS9aa8uGPQtsBtslmZvkktbaK5M8lCd9LNj+mYlkcD72GzP+nzK7J9khyRFDHQo2g4kQrncnednj7s8YLIMJpapGMh6tn2mt/e1g8b1Vtdvg8d2S/GJY88FGeE2SY6rqzoyfvvH6jJ8juNPgY2mJfTUTx4okK1pr3x/cX5jxkLV/ZqL6gyT/t7U21lpbk+RvM77fto9mQpsI4XpDkpcProQ2JeMnl39pyDPBRhmc//exJLe31v76cQ99KcnbB4r/ahwAAAMVSURBVLffnuTqrT0bbKzW2nmttRmttZkZ3yd/vbV2QpLrkrxl8DTvZyaE1tq/JPlZVb1isOiwJLfF/pmJ66dJ5lXVCwf//nj0PW0fzYRW459+6VtV/YeMn081OcnHW2sfGPJIsFGq6rVJvpXklvzbOYHnZ/w8188l+XdJ7kryH1tr/zqUIeE5qKpDk/xla+2oqvrdjB+B3SXJD5Oc2Fr79TDngw1RVXMyfqGxKUl+kuRPMv6f+/bPTEhV9b4kb834txr8MMkpGT+n1T6aCWtChCsAAADPXxPho8IAAAA8jwlXAAAAuiZcAQAA6JpwBQAAoGvCFQAAgK4JVwDYQqpqXVXd9Lhf527Gdc+squWba30A0LPthj0AAGzDftVamzPsIQBgonPEFQC2sqq6s6r+e1XdUlU/qKrfGyyfWVVfr6p/rKqvVdW/Gyx/SVUtqqqbB7/+/WBVk6vqsqq6tar+oaq2Hzz/9Kq6bbCeK4f0YwLAZiNcAWDL2f5JHxV+6+MeW9lam5XkfyX50GDZh5Nc0Vo7IMlnklw8WH5xkm+21mYnmZvk1sHylyf5SGttvyQPJDlusPzcJK8crOcdW+qHA4CtpVprw54BALZJVbW6tbbj0yy/M8nrW2s/qaqRJP/SWptWVfcl2a21tmaw/J7W2m9X1ViSGa21Xz9uHTOTXNtae/ng/jlJRlpr/7WqrkmyOskXk3yxtbZ6C/+oALBFOeIKAMPRnuH2xvj1426vy79du+LIJB/J+NHZG6rKNS0AmNCEKwAMx1sf9/uSwe3vJnnb4PYJSb41uP21JH+RJFU1uap+65lWWlWTkrystXZdknOS/FaSpxz1BYCJxP/AAsCWs31V3fS4+9e01h79Spydq+ofM37U9PjBsncl+URVnZ1kLMmfDJafkeSjVfVnGT+y+hdJ7nmGbU5O8ulB3FaSi1trD2y2nwgAhsA5rgCwlQ3OcR1trd037FkAYCLwUWEAAAC65ogrAAAAXXPEFQAAgK4JVwAAALomXAEAAOiacAUAAKBrwhUAAICuCVcAAAC69v8BFoj0NVKhnjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_history(histories, key='mae'):\n",
        "  plt.figure(figsize=(16,10))\n",
        "  for name, history in histories:\n",
        "    val = plt.plot(history.epoch, history.history['val_'+key],\n",
        "                   '--', label=name.title()+' Val')\n",
        "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
        "             label=name.title()+' Train')\n",
        "\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(key.replace('_',' ').title())\n",
        "  plt.legend()\n",
        "\n",
        "  plt.xlim([0,max(history.epoch)])\n",
        "  plt.ylim([-1,5])\n",
        "\n",
        "plot_history([('baseline', baseline_history)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiWUu8BsGEFt"
      },
      "source": [
        "7. Trying to regularize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sIoMOIsja3g"
      },
      "outputs": [],
      "source": [
        "l1_model = keras.Sequential([ keras.layers.Dense(32, kernel_regularizer=keras.regularizers.l1(0.1), activation=tf.nn.relu,\n",
        "                       input_shape=(train_x.shape[1],)),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(32, use_bias=True, kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "l1_model.compile(loss='mse',\n",
        "                optimizer=\"rmsprop\",\n",
        "                metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1xBl6iwGeer",
        "outputId": "da8f10d3-554c-4305-a0ca-6e72fd40ce59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 32)                672       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,041\n",
            "Trainable params: 7,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "l1_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRfBaBgTjex6",
        "outputId": "0fcc01cc-9baf-4fb7-eafb-5c6ca5ac3774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "128/128 [==============================] - 2s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 2/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 3/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 4/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 5/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 6/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 7/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 8/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 9/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 10/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 11/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 12/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 13/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 14/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 15/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 16/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 17/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 18/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 19/100\n",
            "128/128 [==============================] - 1s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 20/100\n",
            "128/128 [==============================] - 1s 6ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 21/100\n",
            "128/128 [==============================] - 1s 5ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 22/100\n",
            "128/128 [==============================] - 1s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 23/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 24/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 25/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 26/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 27/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 28/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 29/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 30/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 31/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 32/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 33/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 34/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 35/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 36/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 37/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 38/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 39/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 40/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 41/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 42/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 43/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 44/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 45/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 46/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 47/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 48/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 49/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 50/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 51/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 52/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 53/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 54/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 55/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 56/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 57/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 58/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 59/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 60/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 61/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 62/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 63/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 64/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 65/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 66/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 67/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 68/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 69/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 70/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 71/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 72/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 73/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 74/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 75/100\n",
            "128/128 [==============================] - 0s 4ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 76/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 77/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 78/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 79/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 80/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 81/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 82/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 83/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 84/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 85/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 86/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 87/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 88/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 89/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 90/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 91/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 92/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 93/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 94/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 95/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 96/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 97/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 98/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 99/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 100/100\n",
            "128/128 [==============================] - 0s 3ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "l1_history = l1_model.fit(train_x,\n",
        "                    train_y,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (valid_x, valid_y))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sNVTbqt3GyRo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y_YjW8OnG1kS",
        "outputId": "58426bf9-e403-497f-dab6-7cc22c9a5412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(min(l1_history.history['val_mae'])) #ACCURACY OF THE L1_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X1n-WU3qjuc6",
        "outputId": "a331862c-39d5-4b62-8503-9e29a3152680"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot history Multiple\n",
        "plot_history([('baseline', baseline_history),\n",
        "              ('L1', l1_history)])\n",
        "             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aDLnl4jBdxLV",
        "outputId": "901ce3fa-4711-4462-dedb-310453bdb731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(min(baseline_history.history['val_mae']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5ejrhzrTdxab",
        "outputId": "84c5d577-853d-4b53-c381-57a429fa3e74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0676119464239628"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y.mad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TQyC7axddxg9",
        "outputId": "644565b1-b6b9-4da5-acfa-5ebee3035abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan\n"
          ]
        }
      ],
      "source": [
        "print(min(l1_history.history['val_mae'])) \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}